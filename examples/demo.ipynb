{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiftyPET Example\n",
    "\n",
    "This is a full demo of NiftyPET's default [OSEM](#OSEM \"ordered subsets expectation maximisation\") ($n_\\text{max}=14$ subsets, span 11, Siemens Biograph mMR resolution), as well as a custom, explicit [MLEM](#MLEM \"maximum likelihood expectation maximisation\") incorporating [RM](#RM \"resolution modelling\").\n",
    "\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$\n",
    "{\\bf y}^{(k+1)} = {{\\bf y}^{(k)} \\over \\sum_n{{\\bf H}^T{\\bf X}_n^T{\\bf A}^T{\\bf N}^T{\\bf 1}}}\n",
    "    \\circ\n",
    "    \\sum_n{ {\\bf H}^T{\\bf X}_n^T{\\bf A}^T{\\bf N}^T\n",
    "        { {\\bf m} \\over {\\bf NA}{\\bf X}_n{\\bf H}{\\bf y}^{(k)} + {\\bf r} + {\\bf s} }\n",
    "    },\n",
    "$$\n",
    "\n",
    "- $k$ is iteration number\n",
    "- $H$ applies a Gaussian PSF\n",
    "- $X_n$ is the system matrix for subset $n$ (MLEM has just one subset)\n",
    "- $m, r, s$ are measured, randoms, and scatter\n",
    "\n",
    "----\n",
    "\n",
    "- Author: Casper O. da Costa-Luis [casper.dcl@{physics.org|ieee.org|ucl.ac.uk|kcl.ac.uk}](mailto:casper.dcl@physics.org)\n",
    "- Date: 2019-21\n",
    "\n",
    "----\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib notebook\n",
    "\n",
    "import logging\n",
    "from functools import partial\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "import cuvec as cu\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from niftypet import nipet, nimpa\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=nipet.LOG_FORMAT)\n",
    "print(nipet.gpuinfo())\n",
    "# get all the scanner parameters\n",
    "mMRpars = nipet.get_mmrparams()\n",
    "mMRpars['Cnt']['LOG'] = logging.INFO\n",
    "# conversion for Gaussian sigma/[voxel] to FWHM/[mm]\n",
    "SIGMA2FWHMmm = (8 * np.log(2))**0.5 * np.array([mMRpars['Cnt']['SO_VX' + i] for i in 'ZYX']) * 10\n",
    "# image-space PSF function\n",
    "imsmooth = partial(nimpa.imsmooth, Cnt=mMRpars['Cnt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Process Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderin = Path(\"amyloidPET_FBP_TP0\")\n",
    "# automatically categorise the input data\n",
    "datain = nipet.classify_input(folderin, mMRpars)\n",
    "# output path\n",
    "opth = Path(datain['corepath']) / \"niftyout\"\n",
    "# show categorised data\n",
    "datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardware mu-map (bed, head/neck coils)\n",
    "mu_h = nipet.hdw_mumap(datain, [1, 2, 4], mMRpars, outpath=opth, use_stored=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram\n",
    "mMRpars['Cnt']['BTP'] = 0\n",
    "mSino = nipet.mmrhist(datain, mMRpars, outpath=opth, store=True, use_stored=True)\n",
    "if False:                                                   # enable parametric bootstrap\n",
    "    mMRpars['Cnt']['BTP'] = 2\n",
    "    totCnt = 3e6                                            # total counts to simulate\n",
    "    mMRpars['Cnt']['BTPRT'] = totCnt / mSino['psino'].sum() # count level ratio relative to original\n",
    "    mSino = nipet.mmrhist(datain, mMRpars, outpath=opth / \"BTP\" / f\"{totCnt:.3g}\", store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MR-based human mu-map\n",
    "if True:                        # UTE-based object mu-map aligned (need UTE sequence or T1 for pseudo-CT)\n",
    "    mu_o = nipet.align_mumap(\n",
    "        datain,\n",
    "        scanner_params=mMRpars,\n",
    "        outpath=opth,\n",
    "        store=True,\n",
    "        use_stored=True,\n",
    "        hst=mSino,\n",
    "        t0=0,\n",
    "        t1=0,                   # when both times are 0, will use full data\n",
    "        itr=2,                  # number of iterations used for recon to which registering MR/UTE\n",
    "        petopt='ac',            # what PET image to use (ac-just attenuation corrected)\n",
    "        musrc='pct',            # source of mu-map (ute/pct)\n",
    "        ute_name='UTE2',        # which UTE to use (UTE1/2 shorter/faster)\n",
    "    )\n",
    "else:                           # the same as above without any faff though (no alignment)\n",
    "    mu_o = nipet.obj_mumap(datain, mMRpars, outpath=opth, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mu = mu_h['im'] + mu_o['im'] # needs HW mu-maps\n",
    "except (NameError, KeyError):\n",
    "    mu = mu_o['im']\n",
    "    mu_h = {'im': np.zeros_like(mu_o['im'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimpa.imscroll(mu, titles=[r\"$\\mu$-map\"], cmap='bone');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinogram index (<127 for direct sinograms, >=127 for oblique sinograms)\n",
    "nimpa.imscroll(\n",
    "    {\n",
    "        f\"Prompt sinogram ({mSino['psino'].sum() / 1e6:.3g}M)\": mSino['psino'],\n",
    "        f\"Delayed sinogram ({mSino['dsino'].sum() / 1e6:.3g}M)\": mSino['dsino']}, cmap='inferno',\n",
    "    fig=plt.figure(num=2, figsize=(9.5, 3.5)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSEM\n",
    "\n",
    "Note that since $\\bf A$ and $\\bf N$ are both diagonal matrix operators, the reconstruction equation can be slightly rewritten to reduce the number of calculations required per iteration:\n",
    "\n",
    "$$\n",
    "{\\bf y}^{(k+1)} = {{\\bf y}^{(k)} \\over \\sum_n{{\\bf H}^T{\\bf X}_n^T{\\bf A}^T{\\bf N}^T{\\bf 1}}}\n",
    "    \\circ\n",
    "    \\sum_n{ {\\bf H}^T{\\bf X}_n^T\n",
    "        { {\\bf m} \\over {\\bf X}_n{\\bf H}{\\bf y}^{(k)} + ({\\bf r} + {\\bf s})/{({\\bf A}^T{\\bf N}^T {\\bf 1})} }\n",
    "    },\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "psf = nipet.prj.mmrrec.psf_config('measured', mMRpars['Cnt'])\n",
    "msk = nipet.get_cylinder(mMRpars['Cnt'], rad=29., xo=0., yo=0., unival=1, gpu_dim=True) > 0.9\n",
    "\n",
    "## Attenuation, Normalisation & Sensitivity\n",
    "A = nipet.frwd_prj(mu, mMRpars, attenuation=True, dev_out=True) # imsmooth(mu, psf=psf)\n",
    "N = nipet.mmrnorm.get_norm_sino(datain, mMRpars, mSino, gpu_dim=True)\n",
    "AN = cu.asarray(A * N)\n",
    "\n",
    "Sn = 14                   # number of subsets\n",
    "sinoTIdx = [None] * Sn    # subset indices\n",
    "sen = [None] * Sn         # sensitivity images for each subset\n",
    "sen_inv_msk = [None] * Sn # masked inverse sensitivity image\n",
    "\n",
    "for n in trange(Sn, unit=\"subset\"):\n",
    "    sinoTIdx[n] = cu.asarray(nipet.prj.mmrrec.get_subsets14(n, mMRpars)[0], 'int32')\n",
    "    sen[n] = nipet.back_prj(nimpa.isub(AN, sinoTIdx[n]), mMRpars, isub=sinoTIdx[n], dev_out=True,\n",
    "                            sync=False)\n",
    "    imsmooth(sen[n], psf=psf, output_array=sen[n])\n",
    "    assert sen[n].shape == (mMRpars['Cnt']['SZ_IMX'], mMRpars['Cnt']['SZ_IMY'],\n",
    "                            mMRpars['Cnt']['SZ_IMZ'])\n",
    "    sen_inv_msk[n] = cu.zeros_like(sen[n])\n",
    "    sen_inv_msk[n][msk] = np.float32(1) / sen[n][msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randoms\n",
    "\n",
    "r = nipet.randoms(mSino, mMRpars)[0]\n",
    "print(\"Randoms: %.3g%%\" % (r.sum() / mSino['psino'].sum() * 100))\n",
    "\n",
    "## Scatter\n",
    "\n",
    "# Estimated image from two OSEM iterations (implicitly using voxel-driven scatter model)\n",
    "eim = nipet.mmrchain(datain, mMRpars, mu_h=mu_h, mu_o=mu_o, itr=2, histo=mSino, outpath=opth)['im']\n",
    "# Recalculate scatter\n",
    "s = nipet.vsm(datain, (mu_h['im'], mu_o['im']), eim, mMRpars, histo=mSino, rsino=r)\n",
    "\n",
    "# normalised randoms + scatter in GPU dimensions\n",
    "r = nipet.mmraux.remgaps(r, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "s = nipet.mmraux.remgaps(s, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "rs_AN = nimpa.div(r + s, AN, default=1)\n",
    "print(\"Scatter: %.3g%%\" % (s.sum() / mSino['psino'].sum() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cu.ones_like(sen[0])             # reconstructed image\n",
    "Hy, XHy, crr, bim, mul = (None,) * 5 # temporary variables\n",
    "m = cu.asarray(nipet.mmraux.remgaps(mSino['psino'], mMRpars['txLUT'], mMRpars['Cnt']))\n",
    "rs_AN_sub = [nimpa.isub(rs_AN, idx) for idx in sinoTIdx]\n",
    "\n",
    "for k in trange(4, desc=\"OSEM\"):\n",
    "    for n in trange(Sn, unit=\"subset\", leave=False):\n",
    "        # forward-project current reconstruction to sinogram space\n",
    "        Hy = imsmooth(y, psf=psf, output_array=Hy, sync=False)\n",
    "        XHy = nipet.frwd_prj(Hy, mMRpars, isub=sinoTIdx[n], attenuation=False, dev_out=True,\n",
    "                             fullsino_out=False, output=XHy, sync=False)\n",
    "        # add randoms and scatter estimates\n",
    "        if False:\n",
    "            # recalculate scatter\n",
    "            s = nipet.vsm(datain, (mu_h['im'], mu_o['im']), y, mMRpars, histo=mSino, rsino=r)\n",
    "            s = nipet.mmraux.remgaps(s, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "            rs_AN = nimpa.div(nimpa.add(nimpa.isub(r, sinoTIdx[n]), nimpa.isub(s, sinoTIdx[n])),\n",
    "                              nimpa.isub(AN, sinoTIdx[n]), default=1)\n",
    "            XHy = nimpa.add(XHy, rs_AN, output=XHy, sync=False)\n",
    "        else:\n",
    "            XHy = nimpa.add(XHy, rs_AN_sub[n], output=XHy, sync=False)\n",
    "\n",
    "        # measured sinogram subset\n",
    "        crr = nimpa.isub(m, sinoTIdx[n], output=crr, sync=False)\n",
    "        # corrections\n",
    "        crr = nimpa.div(crr, XHy, default=1, output=crr, sync=False)\n",
    "        # back-project corrections to image space\n",
    "        bim = nipet.back_prj(crr, mMRpars, isub=sinoTIdx[n], dev_out=True, output=bim, sync=False)\n",
    "        mul = imsmooth(bim, psf=psf, output_array=mul, sync=False)\n",
    "        # apply FOV mask and normalise with scanner sensitivity\n",
    "        mul = nimpa.mul(mul, sen_inv_msk[n], output=mul, sync=False)\n",
    "        # update reconstructed image\n",
    "        y = nimpa.mul(y, mul, output=y, sync=False)\n",
    "cu.dev_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimpa.imscroll(nipet.img.mmrimg.convert2e7(y, mMRpars['Cnt']), cmap='magma', vmin=0, vmax=np.percentile(y, 99.95));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "psf = nipet.prj.mmrrec.psf_config('measured', mMRpars['Cnt'])\n",
    "msk = nipet.get_cylinder(mMRpars['Cnt'], rad=29., xo=0., yo=0., unival=1, gpu_dim=True) > 0.9\n",
    "\n",
    "## Randoms\n",
    "\n",
    "r = nipet.randoms(mSino, mMRpars)[0]\n",
    "print(\"Randoms: %.3g%%\" % (r.sum() / mSino['psino'].sum() * 100))\n",
    "\n",
    "## Scatter\n",
    "\n",
    "# Estimated image from two OSEM iterations (implicitly using voxel-driven scatter model)\n",
    "eim = nipet.mmrchain(datain, mMRpars, mu_h=mu_h, mu_o=mu_o, itr=2, histo=mSino, outpath=opth)['im']\n",
    "# Recalculate scatter\n",
    "s = nipet.vsm(datain, (mu_h['im'], mu_o['im']), eim, mMRpars, histo=mSino, rsino=r)\n",
    "print(\"Scatter: %.3g%%\" % (s.sum() / mSino['psino'].sum() * 100))\n",
    "\n",
    "# normalised randoms + scatter in GPU dimensions\n",
    "r = nipet.mmraux.remgaps(r, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "s = nipet.mmraux.remgaps(s, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "\n",
    "## Attenuation, Normalisation & Sensitivity\n",
    "A = nipet.frwd_prj(mu, mMRpars, attenuation=True, dev_out=True)\n",
    "N = nipet.mmrnorm.get_norm_sino(datain, mMRpars, mSino, gpu_dim=True)\n",
    "AN = cu.asarray(A * N)\n",
    "rs_AN = nimpa.div(r + s, AN, default=1)\n",
    "\n",
    "sim = nipet.back_prj(AN, mMRpars, dev_out=True, sync=False)\n",
    "imsmooth(sim, psf=psf, output_array=sim)\n",
    "sim_inv_msk = cu.zeros_like(sim)\n",
    "sim_inv_msk[msk] = np.float32(1) / sim[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Attenuation\": A, \"Normalisation\": N, \"Scatter\": s, \"Randoms\": r\n",
    "nimpa.imscroll({\"Prompts\": mSino['psino'], \"Delayed\": mSino['dsino']}, cmap='inferno',\n",
    "               fig=plt.figure(num=4, figsize=(9.5, 3.5)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLEM with RM\n",
    "y = [np.ones_like(sim)]              # reconstructed image\n",
    "Hy, XHy, crr, bim, mul = (None,) * 5 # temporary variables\n",
    "m = cu.asarray(nipet.mmraux.remgaps(mSino['psino'], mMRpars['txLUT'], mMRpars['Cnt']))\n",
    "\n",
    "for k in trange(4 * 14, desc=\"MLEM\"):\n",
    "    # forward-project current reconstruction to sinogram space\n",
    "    Hy = imsmooth(y[-1], psf=psf, output_array=Hy, sync=False)\n",
    "    XHy = nipet.frwd_prj(Hy, mMRpars, dev_out=True, fullsino_out=False, output=XHy, sync=False)\n",
    "    # add randoms and scatter estimates\n",
    "    if False:\n",
    "        # recalculate scatter\n",
    "        s = nipet.vsm(datain, (mu_h['im'], mu_o['im']), y[-1], mMRpars, histo=mSino, rsino=r)\n",
    "        s = nipet.mmraux.remgaps(s, mMRpars['txLUT'], mMRpars['Cnt'])\n",
    "        rs_AN = nimpa.div(r + s, AN, default=1)\n",
    "    XHy = nimpa.add(XHy, rs_AN, output=XHy, sync=False)\n",
    "\n",
    "    # corrections\n",
    "    crr = nimpa.div(m, XHy, default=1, output=crr, sync=False)\n",
    "    # back-project corrections to image space\n",
    "    bim = nipet.back_prj(crr, mMRpars, dev_out=True, output=bim, sync=False)\n",
    "    mul = imsmooth(bim, psf=psf, output_array=mul, sync=False)\n",
    "    # apply FOV mask and normalise with scanner sensitivity\n",
    "    mul = nimpa.mul(mul, sim_inv_msk, output=mul, sync=False)\n",
    "    # update reconstructed image\n",
    "    y.append(nimpa.mul(y[-1], mul, sync=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# central slice across iterations\n",
    "nimpa.imscroll(\n",
    "    {\n",
    "        f\"{k}\": nipet.img.mmrimg.convert2e7(y[k], mMRpars['Cnt'])[:, 90:-100, 110:-110]\n",
    "        for k in range(7, len(y), 7)}, cmap='magma', vmin=0, vmax=np.percentile(y[-1], 99.95),\n",
    "    fig=plt.figure(num=6, figsize=(9.5, 3.5)));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:niftypet]",
   "language": "python",
   "name": "conda-env-niftypet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
